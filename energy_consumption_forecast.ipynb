{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "994605c7",
   "metadata": {},
   "source": [
    "### Time Series Forecasting\n",
    "\n",
    "- A time series is data collected periodically, over time.\n",
    "- Time series forecasting is the task of predicting future data points, given some historical data.\n",
    "- It is commonly used in a variety of tasks from weather forecasting, retail and sales forecasting, stock market prediction, and in behavior prediction (such as predicting the flow of car traffic over a day).\n",
    "- There is a lot of time series data out there, and recognizing patterns in that data is an active area of machine learning research!\n",
    "\n",
    "* In this notebook, we'll focus on one method for finding time-based patterns: using SageMaker's supervised learning model, DeepAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec16a68",
   "metadata": {},
   "source": [
    "#### DeepAR\n",
    "\n",
    "- DeepAR utilizes a recurrent neural network(RNN), which is designed to accept some sequence of data points as historical input and produce a predicted sequence of points. So, how does this model learn?\n",
    "\n",
    "- During training, you'll provide a training dataset (made of several time series) to a DeepAR estimator. The estimator looks at all the training time series and tries to identify similarities across them.\n",
    "\n",
    "- It trains by randomly sampling training examples from the training time series.\n",
    "\n",
    "- Each training example consists of a pair of adjacent context and prediction windows of fixed, predefined lengths.\n",
    "    - The context_length parameter controls how far in the past the model can see.\n",
    "    - The prediction_length parameter controls how far in the future predictions can be made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390da19",
   "metadata": {},
   "source": [
    "- In any forecasting task, you should choose the context window to provide enough, relevant information to a model so that it can produce accurate predictions.\n",
    "\n",
    "-  In general, data closest to the prediction time frame will contain the information that is most influential in defining that prediction.\n",
    "\n",
    "- In many forecasting applications, like forecasting sales month-to-month, the context and prediction windows will be the same size, but sometimes it will be useful to have a larger context window to notice longer-term patterns in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc10412",
   "metadata": {},
   "source": [
    "#### Energy Consumption Data\n",
    "\n",
    "- The data we'll be working with in this notebook is data about household electric power consumption, over the globe. The dataset is originally taken from [Kaggle](https://www.kaggle.com/datasets/uciml/electric-power-consumption-data-set), and represents power consumption collected over several years from 2006 to 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baf3dd",
   "metadata": {},
   "source": [
    "#### Machine Learning Workflow\n",
    "\n",
    "This notebook approaches time series forecasting in a number of steps:\n",
    "\n",
    "- Loading and exploring the data\n",
    "- Creating training and test sets of time series\n",
    "- Formatting data as JSON files and uploading to S3\n",
    "- Instantiating and training a DeepAR estimator\n",
    "- Deploying a model and creating a predictor\n",
    "- Evaluating the predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32384da",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e097988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6039ca",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lines = 10\n",
    "\n",
    "with open('household_power_consumption.txt') as file:\n",
    "    head = [next(file) for line in range(n_lines)]\n",
    "    \n",
    "display(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a75cf",
   "metadata": {},
   "source": [
    "#### Pre-Process the Data\n",
    "\n",
    "- The 'household_power_consumption.txt' file has the following attributes:\n",
    "\n",
    "    - The 'household_power_consumption.txt' file has the following attributes:\n",
    "    - The various data features are separated by semicolons (;)\n",
    "    - Some values are 'nan' or '?', and we'll treat these both as NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d9818",
   "metadata": {},
   "source": [
    "##### Managing NaN values\n",
    "\n",
    "- This DataFrame does include some data points that have missing values.\n",
    "- So far, we've mainly been dropping these values, but there are other ways to handle NaN values, as well.\n",
    "- One technique is to just fill the missing column values with the mean value from that column; this way the added value is likely to be realistic.\n",
    "\n",
    "- The preprocessing_methods.py module will help to load in the original text file as a DataFrame and fill in any NaN values, per column, with the mean feature value.\n",
    "- This technique will be fine for long-term forecasting; if I wanted to do an hourly analysis and prediction, I'd consider dropping the NaN values or taking an average over a small, sliding window rather than an entire column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42eb626",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de77f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_methods import DataFrameOperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt = DataFrameOperations('household_power_consumption.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN column values with *average* column value\n",
    "df = df_opt.fill_nan_with_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aeec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fde2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lines = 10\n",
    "\n",
    "with open('new_household_power_consumption.txt') as file:\n",
    "    head = [next(file) for line in range(n_lines)]\n",
    "    \n",
    "display(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"new_household_power_consumption.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\"Date-Time\", \"Global_active_power\", \"Global_reactive_power\", \"Voltage\",\n",
    "       \"Global_intensity\", \"Sub_metering_1\", \"Sub_metering_2\", \"Sub_metering_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49330162",
   "metadata": {},
   "source": [
    "##### Global Active Power\n",
    "\n",
    "- In this example, we'll want to predict the global active power, which is the household minute-averaged active power (kilowatt), measured across the globe. So, below, I am getting just that column of data and displaying the resultant plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df = df['Global_active_power'].copy()\n",
    "power_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the data \n",
    "plt.figure(figsize=(12,6))\n",
    "# all data points\n",
    "power_df.plot(title='Global active power', color='blue') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c81590",
   "metadata": {},
   "source": [
    "- Since the data is recorded each minute, the above plot contains a lot of values. So, I'm also showing just a slice of data, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc58039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can plot a slice of hourly data\n",
    "end_mins = 1440 # 1440 mins = 1 day\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "power_df[0:end_mins].plot(title='Global active power, over one day', color='blue') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56541ea",
   "metadata": {},
   "source": [
    "##### Hourly vs Daily\n",
    "\n",
    "There is a lot of data, collected every minute, and so I could go one of two ways with my analysis:\n",
    "1. Create many, short time series, say a week or so long, in which I record energy consumption every hour, and try to predict the energy consumption over the following hours or days.\n",
    "2. Create fewer, long time series with data recorded daily that I could use to predict usage in the following weeks or months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa521",
   "metadata": {},
   "source": [
    "- Both tasks are interesting! It depends on whether you want to predict time patterns over a day/week or over a longer time period, like a month.\n",
    "- With the amount of data I have, I think it would be interesting to see longer, recurring trends that happen over several months or over a year.\n",
    "- So, I will resample the 'Global active power' values, recording daily data points as averages over 24-hr periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8413719",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d46cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date-Time'] = pd.to_datetime(df['Date-Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatime_df = df['Date-Time'].copy()\n",
    "datatime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a5bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e07ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_datatime_df = datatime_df.resample(\"D\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample over day (D)\n",
    "freq = '24h'\n",
    "# calculate the mean active power for a day\n",
    "mean_power_df = power_df.resample(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the mean values\n",
    "plt.figure(figsize=(15, 8))\n",
    "mean_power_df.plot(title='Global active power, mean per day', color='blue')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294f97d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
